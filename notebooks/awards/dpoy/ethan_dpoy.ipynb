{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from nba_api.stats.endpoints import leagueleaders\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting ### \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['BLK', 'STL', 'DREB', 'GP', 'MIN', \n",
    "           'BLK_PER_36', 'STL_PER_36', 'DREB_PER_36', 'DEF_SCORE']\n",
    "\n",
    "actual_nominees = {\n",
    "    '2023-24': ['Rudy Gobert', 'Bam Adebayo', 'Victor Wembanyama'],\n",
    "    '2022-23': ['Jaren Jackson Jr.', 'Brook Lopez', 'Evan Mobley'],\n",
    "    '2021-22': ['Marcus Smart', 'Mikal Bridges', 'Rudy Gobert'],\n",
    "    '2020-21': ['Rudy Gobert', 'Ben Simmons', 'Draymond Green'],\n",
    "    '2019-20': ['Giannis Antetokounmpo', 'Anthony Davis', 'Rudy Gobert'],\n",
    "    '2018-19': ['Rudy Gobert', 'Paul George', 'Giannis Antetokounmpo'],\n",
    "    '2017-18': ['Rudy Gobert', 'Joel Embiid', 'Anthony Davis'],\n",
    "    '2016-17': ['Draymond Green', 'Rudy Gobert', 'Kawhi Leonard'],\n",
    "    '2015-16': ['Kawhi Leonard', 'Draymond Green', 'Hassan Whiteside'],\n",
    "    '2014-15': ['Kawhi Leonard', 'Draymond Green', 'DeAndre Jordan']\n",
    "}\n",
    "\n",
    "def get_season_data(season):\n",
    "    blocks = leagueleaders.LeagueLeaders(\n",
    "        season=season,\n",
    "        stat_category_abbreviation='BLK',\n",
    "        per_mode48='PerGame'\n",
    "    ).get_data_frames()[0]\n",
    "    \n",
    "    steals = leagueleaders.LeagueLeaders(\n",
    "        season=season,\n",
    "        stat_category_abbreviation='STL',\n",
    "        per_mode48='PerGame'\n",
    "    ).get_data_frames()[0]\n",
    "    \n",
    "    def_reb = leagueleaders.LeagueLeaders(\n",
    "        season=season,\n",
    "        stat_category_abbreviation='DREB',\n",
    "        per_mode48='PerGame'\n",
    "    ).get_data_frames()[0]\n",
    "    \n",
    "    blocks = blocks[['PLAYER', 'TEAM', 'GP', 'MIN', 'BLK', 'DREB', 'STL']].head(50)\n",
    "    steals = steals[['PLAYER', 'TEAM', 'GP', 'MIN', 'BLK', 'DREB', 'STL']].head(50)\n",
    "    def_reb = def_reb[['PLAYER', 'TEAM', 'GP', 'MIN', 'BLK', 'DREB', 'STL']].head(50)\n",
    "    \n",
    "    all_players = pd.concat([blocks, steals, def_reb]).drop_duplicates(subset=['PLAYER'])\n",
    "    \n",
    "    for stat in ['BLK', 'STL', 'DREB']:\n",
    "        all_players[f'{stat}_PER_36'] = all_players[stat] * 36 / all_players['MIN']\n",
    "    \n",
    "    all_players['DEF_SCORE'] = (\n",
    "        all_players['BLK'] * 2 + \n",
    "        all_players['STL'] * 2 + \n",
    "        all_players['DREB'] * 0.5\n",
    "    ) * (all_players['GP'] / 82)\n",
    "    \n",
    "    all_players['ACTUAL_NOMINEE'] = all_players['PLAYER'].isin(actual_nominees.get(season, []))\n",
    "    \n",
    "    return all_players\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_full_data():\n",
    "    all_seasons_data = []\n",
    "    for season in actual_nominees.keys():\n",
    "        season_data = get_season_data(season)\n",
    "        season_data['SEASON'] = season\n",
    "        all_seasons_data.append(season_data)\n",
    "    return pd.concat(all_seasons_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared data with 1066 rows.\n",
      "\n",
      "--- Model Evaluation: Gradient Boosting ---\n",
      "\n",
      "Gradient Boosting Classifier:\n",
      "Classification Report (Gradient Boosting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.98      0.97       206\n",
      "        True       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.94       214\n",
      "   macro avg       0.48      0.49      0.49       214\n",
      "weighted avg       0.93      0.94      0.93       214\n",
      "\n",
      "ROC-AUC Score (Gradient Boosting): 0.879\n",
      "\n",
      "Feature Importance (Gradient Boosting):\n",
      "       Feature  Importance\n",
      "8    DEF_SCORE    0.338538\n",
      "0          BLK    0.116992\n",
      "3           GP    0.102354\n",
      "6   STL_PER_36    0.097002\n",
      "7  DREB_PER_36    0.080040\n",
      "1          STL    0.079829\n",
      "4          MIN    0.066466\n",
      "5   BLK_PER_36    0.062675\n",
      "2         DREB    0.056103\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def evaluate_model(full_data):\n",
    "    print(\"\\n--- Model Evaluation: Gradient Boosting ---\")\n",
    "    \n",
    "    X = full_data[FEATURES]\n",
    "    y = full_data['ACTUAL_NOMINEE']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(\"\\nGradient Boosting Classifier:\")\n",
    "    gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    y_pred_gb = gb_model.predict(X_test)\n",
    "    y_proba_gb = gb_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(\"Classification Report (Gradient Boosting):\")\n",
    "    print(classification_report(y_test, y_pred_gb))\n",
    "    print(f\"ROC-AUC Score (Gradient Boosting): {roc_auc_score(y_test, y_proba_gb):.3f}\")\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': FEATURES,\n",
    "        'Importance': gb_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Importance (Gradient Boosting):\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    return gb_model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    full_data = prepare_full_data()\n",
    "    print(f\"Prepared data with {len(full_data)} rows.\")\n",
    "    \n",
    "    gb_model = evaluate_model(full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Era DPOY Predictions ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['BLK', 'STL', 'DREB', 'GP', 'MIN', \n",
    "           'BLK_PER_36', 'STL_PER_36', 'DREB_PER_36', 'DEF_SCORE']\n",
    "\n",
    "def get_season_data(season):\n",
    "    blocks = leagueleaders.LeagueLeaders(\n",
    "        season=season,\n",
    "        stat_category_abbreviation='BLK',\n",
    "        per_mode48='PerGame'\n",
    "    ).get_data_frames()[0]\n",
    "    \n",
    "    steals = leagueleaders.LeagueLeaders(\n",
    "        season=season,\n",
    "        stat_category_abbreviation='STL',\n",
    "        per_mode48='PerGame'\n",
    "    ).get_data_frames()[0]\n",
    "    \n",
    "    def_reb = leagueleaders.LeagueLeaders(\n",
    "        season=season,\n",
    "        stat_category_abbreviation='DREB',\n",
    "        per_mode48='PerGame'\n",
    "    ).get_data_frames()[0]\n",
    "    \n",
    "    blocks = blocks[['PLAYER', 'TEAM', 'GP', 'MIN', 'BLK', 'DREB', 'STL']].head(50)\n",
    "    steals = steals[['PLAYER', 'TEAM', 'GP', 'MIN', 'BLK', 'DREB', 'STL']].head(50)\n",
    "    def_reb = def_reb[['PLAYER', 'TEAM', 'GP', 'MIN', 'BLK', 'DREB', 'STL']].head(50)\n",
    "    \n",
    "    all_players = pd.concat([blocks, steals, def_reb]).drop_duplicates(subset=['PLAYER'])\n",
    "    \n",
    "    for stat in ['BLK', 'STL', 'DREB']:\n",
    "        all_players[f'{stat}_PER_36'] = all_players[stat] * 36 / all_players['MIN']\n",
    "    \n",
    "    all_players['DEF_SCORE'] = (\n",
    "        all_players['BLK'] * 2 + \n",
    "        all_players['STL'] * 2 + \n",
    "        all_players['DREB'] * 0.5\n",
    "    ) * (all_players['GP'] / 82)\n",
    "    \n",
    "    return all_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_interval_data(start_year, end_year):\n",
    "    all_seasons_data = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        try:\n",
    "            season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "            season_data = get_season_data(season)\n",
    "            season_data['SEASON'] = season\n",
    "            all_seasons_data.append(season_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for season {season}: {e}\")\n",
    "    return pd.concat(all_seasons_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_31748\\3805615442.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat(all_seasons_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1960-1980 Data ---\n",
      "Top 5 Predicted DPOY Candidates for 2023-24 Season (1960-1980 Data):\n",
      "              PLAYER TEAM  PREDICTED_PROBABILITY  DEF_SCORE\n",
      "0  Victor Wembanyama  SAS               0.999966  11.948780\n",
      "3      Anthony Davis  LAL               0.999966  10.890244\n",
      "1     Walker Kessler  UTA               0.000002   6.439024\n",
      "2        Brook Lopez  MIL               0.000002   7.370122\n",
      "4      Chet Holmgren  OKC               0.000002   8.950000\n",
      "\n",
      "1980-2000 Data ---\n",
      "Top 5 Predicted DPOY Candidates for 2023-24 Season (1980-2000 Data):\n",
      "              PLAYER TEAM  PREDICTED_PROBABILITY  DEF_SCORE\n",
      "0  Victor Wembanyama  SAS               0.999966  11.948780\n",
      "3      Anthony Davis  LAL               0.999966  10.890244\n",
      "1     Walker Kessler  UTA               0.000002   6.439024\n",
      "2        Brook Lopez  MIL               0.000002   7.370122\n",
      "4      Chet Holmgren  OKC               0.000002   8.950000\n",
      "\n",
      "2000-2020 Data ---\n",
      "Top 5 Predicted DPOY Candidates for 2023-24 Season (2000-2020 Data):\n",
      "               PLAYER TEAM  PREDICTED_PROBABILITY  DEF_SCORE\n",
      "0   Victor Wembanyama  SAS               0.999966  11.948780\n",
      "3       Anthony Davis  LAL               0.999966  10.890244\n",
      "4       Chet Holmgren  OKC               0.999966   8.950000\n",
      "5         Rudy Gobert  MIN               0.999966   9.453659\n",
      "37       Nikola Jokić  DEN               0.999966   9.007927\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_and_predict_for_interval(interval_name, data_interval, data_2023_24):\n",
    "    print(f\"\\n{interval_name} Data ---\")\n",
    "    \n",
    "    X = data_interval[FEATURES]\n",
    "    y = (data_interval['DEF_SCORE'] >= data_interval['DEF_SCORE'].quantile(0.95)).astype(int) \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    X_2023_24 = scaler.transform(data_2023_24[FEATURES])\n",
    "    data_2023_24['PREDICTED_PROBABILITY'] = model.predict_proba(X_2023_24)[:, 1]\n",
    "    \n",
    "    top_5_candidates = data_2023_24.nlargest(5, 'PREDICTED_PROBABILITY')\n",
    "    print(f\"Top 5 Predicted DPOY Candidates for 2023-24 Season ({interval_name} Data):\")\n",
    "    print(top_5_candidates[['PLAYER', 'TEAM', 'PREDICTED_PROBABILITY', 'DEF_SCORE']])\n",
    "    \n",
    "    return top_5_candidates\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_1960_1980 = prepare_interval_data(1960, 1980)\n",
    "    data_1980_2000 = prepare_interval_data(1980, 2000)\n",
    "    data_2000_2020 = prepare_interval_data(2000, 2020)\n",
    "    \n",
    "    data_2023_24 = prepare_interval_data(2023, 2024)\n",
    "    \n",
    "    top_5_candidates_1960_1980 = train_and_predict_for_interval(\"1960-1980\", data_1960_1980, data_2023_24)\n",
    "    top_5_candidates_1980_2000 = train_and_predict_for_interval(\"1980-2000\", data_1980_2000, data_2023_24)\n",
    "    top_5_candidates_2000_2020 = train_and_predict_for_interval(\"2000-2020\", data_2000_2020, data_2023_24)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_31748\\3805615442.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat(all_seasons_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Predictions for 1960-1980 Era ---\n",
      "\n",
      "1960-1980 Data ---\n",
      "\n",
      "Top 5 Predicted DPOY Candidates for 2023-24 Season (1960-1980 - Logistic Regression):\n",
      "               PLAYER TEAM  LR_PROBABILITY  DEF_SCORE\n",
      "0   Victor Wembanyama  SAS        0.999887  11.948780\n",
      "3       Anthony Davis  LAL        0.977476  10.890244\n",
      "5         Rudy Gobert  MIN        0.365491   9.453659\n",
      "4       Chet Holmgren  OKC        0.106773   8.950000\n",
      "37       Nikola Jokić  DEN        0.031264   9.007927\n",
      "\n",
      "--- Predictions for 1980-2000 Era ---\n",
      "\n",
      "1980-2000 Data ---\n",
      "\n",
      "Top 5 Predicted DPOY Candidates for 2023-24 Season (1980-2000 - Logistic Regression):\n",
      "               PLAYER TEAM  LR_PROBABILITY  DEF_SCORE\n",
      "0   Victor Wembanyama  SAS        1.000000  11.948780\n",
      "3       Anthony Davis  LAL        0.999865  10.890244\n",
      "5         Rudy Gobert  MIN        0.848058   9.453659\n",
      "37       Nikola Jokić  DEN        0.565917   9.007927\n",
      "4       Chet Holmgren  OKC        0.214815   8.950000\n",
      "\n",
      "--- Predictions for 2000-2020 Era ---\n",
      "\n",
      "2000-2020 Data ---\n",
      "\n",
      "Top 5 Predicted DPOY Candidates for 2023-24 Season (2000-2020 - Logistic Regression):\n",
      "               PLAYER TEAM  LR_PROBABILITY  DEF_SCORE\n",
      "0   Victor Wembanyama  SAS        1.000000  11.948780\n",
      "3       Anthony Davis  LAL        0.999999  10.890244\n",
      "5         Rudy Gobert  MIN        0.996415   9.453659\n",
      "4       Chet Holmgren  OKC        0.968903   8.950000\n",
      "37       Nikola Jokić  DEN        0.956092   9.007927\n"
     ]
    }
   ],
   "source": [
    "def train_and_predict_for_interval(interval_name, data_interval, data_2023_24):\n",
    "    print(f\"\\n{interval_name} Data ---\")\n",
    "    \n",
    "    X = data_interval[FEATURES]\n",
    "    y = (data_interval['DEF_SCORE'] >= data_interval['DEF_SCORE'].quantile(0.95)).astype(int) \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Balanced to ensure for amy imblance within dataset\n",
    "    lr_model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "    lr_model.fit(X, y)\n",
    "    \n",
    "\n",
    "\n",
    "#Normalize features so that each feature has mean of 0 and std of 1. \n",
    "    X_2023_24 = scaler.transform(data_2023_24[FEATURES])\n",
    "    data_2023_24['LR_PROBABILITY'] = lr_model.predict_proba(X_2023_24)[:, 1]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    top_5_lr = data_2023_24.nlargest(5, 'LR_PROBABILITY')\n",
    "    print(f\"\\nTop 5 Predicted DPOY Candidates for 2023-24 Season ({interval_name} - Logistic Regression):\")\n",
    "    print(top_5_lr[['PLAYER', 'TEAM', 'LR_PROBABILITY', 'DEF_SCORE']])\n",
    "    \n",
    "    return top_5_lr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_1960_1980 = prepare_interval_data(1960, 1980)\n",
    "    data_1980_2000 = prepare_interval_data(1980, 2000)\n",
    "    data_2000_2020 = prepare_interval_data(2000, 2020)\n",
    "    \n",
    "    data_2023_24 = prepare_interval_data(2023, 2024)\n",
    "    \n",
    "    print(\"\\n--- Predictions for 1960-1980 Era ---\")\n",
    "    top_5_lr_1960_1980 = train_and_predict_for_interval(\"1960-1980\", data_1960_1980, data_2023_24)\n",
    "    \n",
    "    print(\"\\n--- Predictions for 1980-2000 Era ---\")\n",
    "    top_5_lr_1980_2000 = train_and_predict_for_interval(\"1980-2000\", data_1980_2000, data_2023_24)\n",
    "    \n",
    "    print(\"\\n--- Predictions for 2000-2020 Era ---\")\n",
    "    top_5_lr_2000_2020 = train_and_predict_for_interval(\"2000-2020\", data_2000_2020, data_2023_24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks (Incomplete) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FEATURES = ['BLK', 'STL', 'DREB', 'GP', 'MIN', \n",
    "            'BLK_PER_36', 'STL_PER_36', 'DREB_PER_36', 'DEF_SCORE']\n",
    "\n",
    "def prepare_data(data):\n",
    "    X = data[FEATURES]\n",
    "    y = (data['DEF_SCORE'] >= data['DEF_SCORE'].quantile(0.95)).astype(int)  # Top 5% as DPOY candidates\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "   \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "def train_and_evaluate_svm(data):\n",
    "    X_train, X_test, y_train, y_test, scaler = prepare_data(data)\n",
    "\n",
    "    svm_model = SVC(kernel='rbf', probability=True, class_weight='balanced', random_state=42)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    y_proba = svm_model.predict_proba(X_test)[:, 1] \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
