{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BRScraper import nba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing for ML Model\n",
    "\n",
    "# df = nba.get_stats(season=2023, info='per_game', playoffs=False)\n",
    "# drop_columns = ['Age','Pos', 'GS', '3PA', '2PA', 'PF', 'Awards']\n",
    "# df_cleaned = df.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Joel Embiid', 'Nikola Jokić', 'Giannis Antetokounmpo', 'Jayson Tatum', 'Shai Gilgeous-Alexander', 'Donovan Mitchell', 'Domantas Sabonis', 'Luka Dončić', 'Stephen Curry', 'Jimmy Butler', \"De'Aaron Fox\", 'Jalen Brunson', 'Ja Morant']\n"
     ]
    }
   ],
   "source": [
    "# mvp_data = nba.get_award_votings('mvp', 2023)\n",
    "# nominated_players = mvp_data['Player'].tolist()\n",
    "# print(nominated_players)\n",
    "\n",
    "# creating the 'Previously_Nominated' column, if a player was nominated for MVP mark 1, else mark 0. will help serve as a proxy for player reputation\n",
    "# df_cleaned['Previously_Nominated'] = df_cleaned['Player'].apply(lambda x: 1 if x in nominated_players else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # identifying players who have stats for multiple teams and eliminating duplicates\n",
    "# multi_team_players = df_cleaned[df_cleaned['Team'] == '2TM']['Player'].unique()\n",
    "\n",
    "# # keeping only the row where team value is set to 2TM, this row will include all combined stats and average from all teams the player played for\n",
    "# mask = (df_cleaned['Team'] == '2TM') | (~df_cleaned['Player'].isin(multi_team_players))\n",
    "\n",
    "# df_cleaned = df_cleaned[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating a True Shooting Percentage (TS%) column\n",
    "# # the formula is TS% = PTS / 2 * (FGA + 0.44 * FTA)\n",
    "\n",
    "# if 'PTS' in df_cleaned.columns and 'FGA' in df_cleaned.columns and 'FTA' in df_cleaned.columns:\n",
    "#     df_cleaned['TS%'] = df_cleaned['PTS'] / (2 * (df_cleaned['FGA'] + 0.44 * df_cleaned['FTA']))\n",
    "#     df_cleaned['TS%'] = df_cleaned['TS%'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding another column EEF, stands effeciency. It a metric used by the nba to calculate a player's efficiency or impact.\n",
    "\n",
    "# # calculating missed field goals and missed free throws because the EEF formula requires it.\n",
    "# df_cleaned['Missed_FG'] = df_cleaned['FGA'] - df_cleaned['FG']\n",
    "# df_cleaned['Missed_FT'] = df_cleaned['FTA'] - df_cleaned['FT']\n",
    "\n",
    "# # Calculating EFF\n",
    "# df_cleaned['EFF'] = (\n",
    "#     df_cleaned['PTS'] +\n",
    "#     df_cleaned['TRB'] +\n",
    "#     df_cleaned['AST'] +\n",
    "#     df_cleaned['STL'] +\n",
    "#     df_cleaned['BLK'] -\n",
    "#     df_cleaned['Missed_FG'] -\n",
    "#     df_cleaned['Missed_FT'] -\n",
    "#     df_cleaned['TOV']\n",
    "#     ) / df_cleaned['G']\n",
    "\n",
    "# # dropping the temporary columns, no longer needed\n",
    "# df_cleaned.drop(columns=['Missed_FG', 'Missed_FT'], inplace=True)\n",
    "\n",
    "# # rounded EFF to 2 decimals\n",
    "# df_cleaned['EFF'] = df_cleaned['EFF'].round(2)\n",
    "\n",
    "# output_file = \"nba_2023_adjusted_data.csv\"\n",
    "# df_cleaned.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1980-81 successfully!\n",
      "Processed 1981-82 successfully!\n",
      "Processed 1982-83 successfully!\n",
      "Processed 1983-84 successfully!\n",
      "Processed 1984-85 successfully!\n",
      "Processed 1985-86 successfully!\n",
      "Processed 1986-87 successfully!\n",
      "Processed 1987-88 successfully!\n",
      "Processed 1988-89 successfully!\n",
      "Processed 1989-90 successfully!\n",
      "Processed 1990-91 successfully!\n",
      "Processed 1991-92 successfully!\n",
      "Processed 1992-93 successfully!\n",
      "Processed 1993-94 successfully!\n",
      "Processed 1994-95 successfully!\n",
      "Processed 1995-96 successfully!\n",
      "Processed 1996-97 successfully!\n",
      "Processed 1997-98 successfully!\n",
      "Processed 1998-99 successfully!\n",
      "Processed 1999-00 successfully!\n",
      "Processed 2000-01 successfully!\n",
      "Processed 2001-02 successfully!\n",
      "Processed 2002-03 successfully!\n",
      "Processed 2003-04 successfully!\n",
      "Processed 2004-05 successfully!\n",
      "Processed 2005-06 successfully!\n",
      "Processed 2006-07 successfully!\n",
      "Processed 2007-08 successfully!\n",
      "Processed 2008-09 successfully!\n",
      "Processed 2009-10 successfully!\n"
     ]
    }
   ],
   "source": [
    "# this function is used to preprocess a single season\n",
    "def preprocess_season(file_name, season, mvp_votings):\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    # dropping unnecessary columns\n",
    "    drop_columns = ['Age', 'Pos', 'GS', '3PA', '2PA', 'PF', 'Awards']\n",
    "    df_cleaned = df.drop(columns=drop_columns, errors='ignore')\n",
    "\n",
    "    # handling players who played for multiple teams\n",
    "    multi_team_players = df_cleaned[df_cleaned['Team'] == '2TM']['Player'].unique()\n",
    "    mask = (df_cleaned['Team'] == '2TM') | (~df_cleaned['Player'].isin(multi_team_players))\n",
    "    df_cleaned = df_cleaned[mask]\n",
    "\n",
    "    # calculating TS%\n",
    "    if 'PTS' in df_cleaned.columns and 'FGA' in df_cleaned.columns and 'FTA' in df_cleaned.columns:\n",
    "        df_cleaned['TS%'] = df_cleaned['PTS'] / (2 * (df_cleaned['FGA'] + 0.44 * df_cleaned['FTA']))\n",
    "        df_cleaned['TS%'] = df_cleaned['TS%'].round(2)\n",
    "\n",
    "    # calculating missed shots for EFF\n",
    "    if 'FGA' in df_cleaned.columns and 'FG' in df_cleaned.columns:\n",
    "        df_cleaned['Missed_FG'] = df_cleaned['FGA'] - df_cleaned['FG']\n",
    "    if 'FTA' in df_cleaned.columns and 'FT' in df_cleaned.columns:\n",
    "        df_cleaned['Missed_FT'] = df_cleaned['FTA'] - df_cleaned['FT']\n",
    "\n",
    "    # calculating the EFF metric\n",
    "    if {'PTS', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'G', 'Missed_FG', 'Missed_FT'}.issubset(df_cleaned.columns):\n",
    "        df_cleaned['EFF'] = (\n",
    "            df_cleaned['PTS'] +\n",
    "            df_cleaned['TRB'] +\n",
    "            df_cleaned['AST'] +\n",
    "            df_cleaned['STL'] +\n",
    "            df_cleaned['BLK'] -\n",
    "            df_cleaned['Missed_FG'] -\n",
    "            df_cleaned['Missed_FT'] -\n",
    "            df_cleaned['TOV']\n",
    "        ) / df_cleaned['G']\n",
    "        df_cleaned['EFF'] = df_cleaned['EFF'].round(2)\n",
    "\n",
    "    # dropping the temporary columns becuase they're no longer needed\n",
    "    df_cleaned.drop(columns=['Missed_FG', 'Missed_FT'], inplace=True, errors='ignore')\n",
    "\n",
    "    # adding the Nominated column\n",
    "    df_cleaned['Nominated'] = df_cleaned['Player'].apply(lambda player: 1 if player in mvp_votings else 0)\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "# declaring the folder containing the CSV files and output destination\n",
    "input_folder = \"untouched_seasonal_data\"\n",
    "output_folder = \"processed_data\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# processing files for each season\n",
    "for year in range(1980, 2010):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}.csv\"\n",
    "    output_file = f\"{output_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            # fetching MVP voting data for the season\n",
    "            mvp_data = nba.get_award_votings('mvp', year)\n",
    "            mvp_votings = set(mvp_data['Player'])  # getting the players who were nominated for MVP\n",
    "            \n",
    "            # preprocessing the season data\n",
    "            processed_df = preprocess_season(file_name, year, mvp_votings)\n",
    "            processed_df.to_csv(output_file, index=False)\n",
    "            print(f\"Processed {season} successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {season}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {file_name} not found. Skipping.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a 1 min break before running the next cell to avoid getting locked out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2010-11 successfully!\n",
      "Processed 2011-12 successfully!\n",
      "Processed 2012-13 successfully!\n",
      "Processed 2013-14 successfully!\n",
      "Processed 2014-15 successfully!\n",
      "Processed 2015-16 successfully!\n",
      "Processed 2016-17 successfully!\n",
      "Processed 2017-18 successfully!\n",
      "Processed 2018-19 successfully!\n",
      "Processed 2019-20 successfully!\n",
      "Processed 2020-21 successfully!\n",
      "Processed 2021-22 successfully!\n",
      "Processed 2022-23 successfully!\n",
      "Processed 2023-24 successfully!\n",
      "Processed 2024-25 successfully!\n"
     ]
    }
   ],
   "source": [
    "# declaring the folder containing the CSV files and output destination\n",
    "input_folder = \"untouched_seasonal_data\"\n",
    "output_folder = \"processed_data\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# processing files for each season\n",
    "for year in range(2010, 2025):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}.csv\"\n",
    "    output_file = f\"{output_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            # fetching MVP voting data for the season\n",
    "            mvp_data = nba.get_award_votings('mvp', year)\n",
    "            mvp_votings = set(mvp_data['Player'])\n",
    "            \n",
    "            # preprocessing the season data\n",
    "            processed_df = preprocess_season(file_name, year, mvp_votings)\n",
    "            processed_df.to_csv(output_file, index=False)\n",
    "            print(f\"Processed {season} successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {season}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {file_name} not found. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read data for the 1980 season\n",
      "Successfully read data for the 1981 season\n",
      "Successfully read data for the 1982 season\n",
      "Successfully read data for the 1983 season\n",
      "Successfully read data for the 1984 season\n",
      "Successfully read data for the 1985 season\n",
      "Successfully read data for the 1986 season\n",
      "Successfully read data for the 1987 season\n",
      "Successfully read data for the 1988 season\n",
      "Successfully read data for the 1989 season\n",
      "Successfully read data for the 1990 season\n",
      "Successfully read data for the 1991 season\n",
      "Successfully read data for the 1992 season\n",
      "Successfully read data for the 1993 season\n",
      "Successfully read data for the 1994 season\n",
      "Successfully read data for the 1995 season\n",
      "Successfully read data for the 1996 season\n",
      "Successfully read data for the 1997 season\n",
      "Successfully read data for the 1998 season\n",
      "Successfully read data for the 1999 season\n",
      "Successfully read data for the 2000 season\n",
      "Successfully read data for the 2001 season\n",
      "Successfully read data for the 2002 season\n",
      "Successfully read data for the 2003 season\n",
      "Successfully read data for the 2004 season\n",
      "Successfully read data for the 2005 season\n",
      "Successfully read data for the 2006 season\n",
      "Successfully read data for the 2007 season\n",
      "Successfully read data for the 2008 season\n",
      "Successfully read data for the 2009 season\n",
      "Successfully read data for the 2010 season\n",
      "Successfully read data for the 2011 season\n",
      "Successfully read data for the 2012 season\n",
      "Successfully read data for the 2013 season\n",
      "Successfully read data for the 2014 season\n",
      "Successfully read data for the 2015 season\n",
      "All datasets have been concatenated and saved to 'nba_combined_1980_2015.csv'.\n"
     ]
    }
   ],
   "source": [
    "#Combine all datasets from 1980 to 2015\n",
    "# Define the folder containing the CSV files\n",
    "input_folder = \"processed_data\"\n",
    "output_folder = \"processed_data\"\n",
    "\n",
    "# List to hold dataframes\n",
    "dataframes = []\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Loop through each year from 1980 to 2015\n",
    "for year in range(1980, 2016):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            # Read the dataset for the year\n",
    "            df = pd.read_csv(file_name)\n",
    "        \n",
    "            # Append the dataframe to the list\n",
    "            dataframes.append(df)\n",
    "        \n",
    "            print(f\"Successfully read data for the {year} season\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read data for {year} season. Error: {e}\")\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "nba_combined_1980_2015 = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the combined dataframe to a CSV file\n",
    "nba_combined_1980_2015.to_csv(\"nba_combined_1980_2015.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\"All datasets have been concatenated and saved to 'nba_combined_1980_2015.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read data for the 2016 season\n",
      "Successfully read data for the 2017 season\n",
      "Successfully read data for the 2018 season\n",
      "Successfully read data for the 2019 season\n",
      "Successfully read data for the 2020 season\n",
      "Successfully read data for the 2021 season\n",
      "Successfully read data for the 2022 season\n",
      "Successfully read data for the 2023 season\n",
      "Successfully read data for the 2024 season\n",
      "All datasets have been concatenated and saved to 'nba_combined_2016_2024.csv'.\n"
     ]
    }
   ],
   "source": [
    "#Combine all datasets from 2016 to 2024\n",
    "# Define the folder containing the CSV files\n",
    "input_folder = \"processed_data\"\n",
    "output_folder = \"processed_data\"\n",
    "\n",
    "# List to hold dataframes\n",
    "dataframes = []\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Loop through each year from 2016 to 2024\n",
    "for year in range(2016, 2025):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            # Read the dataset for the year\n",
    "            df = pd.read_csv(file_name)\n",
    "        \n",
    "            # Append the dataframe to the list\n",
    "            dataframes.append(df)\n",
    "        \n",
    "            print(f\"Successfully read data for the {year} season\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read data for {year} season. Error: {e}\")\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "nba_combined_2016_2024 = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the combined dataframe to a CSV file\n",
    "nba_combined_2016_2024.to_csv(\"nba_combined_2016_2024.csv\", index=False)\n",
    "\n",
    "print(\"All datasets have been concatenated and saved to 'nba_combined_2016_2024.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the Team_Rank column to see how it improves the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1980-81 successfully!\n",
      "Processed 1981-82 successfully!\n",
      "Processed 1982-83 successfully!\n",
      "Processed 1983-84 successfully!\n",
      "Processed 1984-85 successfully!\n",
      "Processed 1985-86 successfully!\n",
      "Processed 1986-87 successfully!\n",
      "Processed 1987-88 successfully!\n",
      "Processed 1988-89 successfully!\n",
      "Processed 1989-90 successfully!\n",
      "Processed 1990-91 successfully!\n",
      "Processed 1991-92 successfully!\n",
      "Processed 1992-93 successfully!\n",
      "Processed 1993-94 successfully!\n"
     ]
    }
   ],
   "source": [
    "# team name mapping\n",
    "team_name_mapping = {\n",
    "    \"ATL\": \"Atlanta Hawks\",\n",
    "    \"BOS\": \"Boston Celtics\",\n",
    "    \"BRK\": \"Brooklyn Nets\",\n",
    "    \"CHO\": \"Charlotte Hornets\",\n",
    "    \"CHI\": \"Chicago Bulls\",\n",
    "    \"CLE\": \"Cleveland Cavaliers\",\n",
    "    \"DAL\": \"Dallas Mavericks\",\n",
    "    \"DEN\": \"Denver Nuggets\",\n",
    "    \"DET\": \"Detroit Pistons\",\n",
    "    \"GSW\": \"Golden State Warriors\",\n",
    "    \"HOU\": \"Houston Rockets\",\n",
    "    \"IND\": \"Indiana Pacers\",\n",
    "    \"LAC\": \"Los Angeles Clippers\",\n",
    "    \"LAL\": \"Los Angeles Lakers\",\n",
    "    \"MEM\": \"Memphis Grizzlies\",\n",
    "    \"MIA\": \"Miami Heat\",\n",
    "    \"MIL\": \"Milwaukee Bucks\",\n",
    "    \"MIN\": \"Minnesota Timberwolves\",\n",
    "    \"NOP\": \"New Orleans Pelicans\",\n",
    "    \"NYK\": \"New York Knicks\",\n",
    "    \"OKC\": \"Oklahoma City Thunder\",\n",
    "    \"ORL\": \"Orlando Magic\",\n",
    "    \"PHI\": \"Philadelphia 76ers\",\n",
    "    \"PHX\": \"Phoenix Suns\",\n",
    "    \"POR\": \"Portland Trail Blazers\",\n",
    "    \"SAC\": \"Sacramento Kings\",\n",
    "    \"SAS\": \"San Antonio Spurs\",\n",
    "    \"TOR\": \"Toronto Raptors\",\n",
    "    \"UTA\": \"Utah Jazz\",\n",
    "    \"WAS\": \"Washington Wizards\",\n",
    "    \"SDC\": \"San Diego Clippers\",\n",
    "    \"NJN\": \"New Jersey Nets\",\n",
    "    \"PHO\": \"Phoenix Suns\",\n",
    "    \"WSB\": \"Washington Bullets\",\n",
    "    \"SEA\": \"Seattle SuperSonics\",\n",
    "    \"CHH\": \"Charlotte Hornets\",\n",
    "    \"VAN\": \"Vancouver Grizzlies\",\n",
    "    \"NOH\": \"New Orleans Hornets\"\n",
    "}\n",
    "\n",
    "def get_team_rankings(year):\n",
    "    standings = nba.get_standings(year, info='total')\n",
    "\n",
    "    # process team names to remove asterisks and determine playoff status\n",
    "    standings[\"Made_Playoffs\"] = standings[\"Tm\"].apply(lambda x: 1 if \"*\" in x else 0)\n",
    "    standings[\"Tm\"] = standings[\"Tm\"].apply(lambda x: x.replace(\"*\", \"\").strip())\n",
    "\n",
    "    standings_dict = dict(zip(standings[\"Tm\"], standings[\"Seed\"]))\n",
    "    playoffs_dict = dict(zip(standings[\"Tm\"], standings[\"Made_Playoffs\"]))\n",
    "    return standings_dict, playoffs_dict\n",
    "\n",
    "# function to preprocess a single season\n",
    "def preprocess_season(file_name, year, mvp_votings):\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    # dropping unnecessary columns\n",
    "    drop_columns = ['Age', 'Pos', 'GS', '3PA', '2PA', 'PF', 'Awards']\n",
    "    df_cleaned = df.drop(columns=drop_columns, errors='ignore')\n",
    "\n",
    "    # handling players who played for multiple teams\n",
    "    multi_team_players = df_cleaned[df_cleaned['Team'] == '2TM']['Player'].unique()\n",
    "    mask = (df_cleaned['Team'] == '2TM') | (~df_cleaned['Player'].isin(multi_team_players))\n",
    "    df_cleaned = df_cleaned[mask]\n",
    "\n",
    "    # calculating TS%\n",
    "    if 'PTS' in df_cleaned.columns and 'FGA' in df_cleaned.columns and 'FTA' in df_cleaned.columns:\n",
    "        df_cleaned['TS%'] = df_cleaned['PTS'] / (2 * (df_cleaned['FGA'] + 0.44 * df_cleaned['FTA']))\n",
    "        df_cleaned['TS%'] = df_cleaned['TS%'].round(2)\n",
    "\n",
    "    # calculating missed shots for EFF\n",
    "    if 'FGA' in df_cleaned.columns and 'FG' in df_cleaned.columns:\n",
    "        df_cleaned['Missed_FG'] = df_cleaned['FGA'] - df_cleaned['FG']\n",
    "    if 'FTA' in df_cleaned.columns and 'FT' in df_cleaned.columns:\n",
    "        df_cleaned['Missed_FT'] = df_cleaned['FTA'] - df_cleaned['FT']\n",
    "\n",
    "    # calculating the EFF metric\n",
    "    if {'PTS', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'G', 'Missed_FG', 'Missed_FT'}.issubset(df_cleaned.columns):\n",
    "        df_cleaned['EFF'] = (\n",
    "            df_cleaned['PTS'] +\n",
    "            df_cleaned['TRB'] +\n",
    "            df_cleaned['AST'] +\n",
    "            df_cleaned['STL'] +\n",
    "            df_cleaned['BLK'] -\n",
    "            df_cleaned['Missed_FG'] -\n",
    "            df_cleaned['Missed_FT'] -\n",
    "            df_cleaned['TOV']\n",
    "        ) / df_cleaned['G']\n",
    "        df_cleaned['EFF'] = df_cleaned['EFF'].round(2)\n",
    "\n",
    "    # dropping the temporary columns\n",
    "    df_cleaned.drop(columns=['Missed_FG', 'Missed_FT'], inplace=True, errors='ignore')\n",
    "\n",
    "    # adding the Nominated column\n",
    "    df_cleaned['Nominated'] = df_cleaned['Player'].apply(lambda player: 1 if player in mvp_votings else 0)\n",
    "\n",
    "    # getting the team standings and then adding the Team_Rank & Made_Playoffs column\n",
    "    team_standings, playoffs_dict = get_team_rankings(year + 1)\n",
    "    df_cleaned['Team_Full'] = df_cleaned['Team'].map(team_name_mapping)\n",
    "    df_cleaned['Team_Rank'] = df_cleaned['Team_Full'].map(team_standings).fillna(-1).astype(int)\n",
    "    df_cleaned['Made_Playoffs'] = df_cleaned['Team_Full'].map(playoffs_dict).fillna(0).astype(int)\n",
    "    df_cleaned.drop(columns=['Team_Full'], inplace=True)\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "input_folder = \"untouched_seasonal_data\"\n",
    "output_folder = \"processed_data_with_Team_Rank\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# processing files for each season\n",
    "for year in range(1980, 1994):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}.csv\"\n",
    "    output_file = f\"{output_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            # fetching MVP voting data for the season\n",
    "            mvp_data = nba.get_award_votings('mvp', year)\n",
    "            mvp_votings = set(mvp_data['Player'])\n",
    "            \n",
    "            # preprocessing the season data\n",
    "            processed_df = preprocess_season(file_name, year, mvp_votings)\n",
    "            processed_df.to_csv(output_file, index=False)\n",
    "            print(f\"Processed {season} successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {season}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {file_name} not found. Skipping.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a 1 min break before running the next cell to avoid getting locked out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1994-95 successfully!\n",
      "Processed 1995-96 successfully!\n",
      "Processed 1996-97 successfully!\n",
      "Processed 1997-98 successfully!\n",
      "Processed 1998-99 successfully!\n",
      "Processed 1999-00 successfully!\n",
      "Processed 2000-01 successfully!\n",
      "Processed 2001-02 successfully!\n",
      "Processed 2002-03 successfully!\n",
      "Processed 2003-04 successfully!\n",
      "Processed 2004-05 successfully!\n",
      "Processed 2005-06 successfully!\n",
      "Processed 2006-07 successfully!\n",
      "Processed 2007-08 successfully!\n"
     ]
    }
   ],
   "source": [
    "# continuation 1994-2007\n",
    "input_folder = \"untouched_seasonal_data\"\n",
    "output_folder = \"processed_data_with_Team_Rank\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# processing files for each season\n",
    "for year in range(1994, 2008):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}.csv\"\n",
    "    output_file = f\"{output_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            # fetching MVP voting data for the season\n",
    "            mvp_data = nba.get_award_votings('mvp', year)\n",
    "            mvp_votings = set(mvp_data['Player']) \n",
    "            \n",
    "            # preprocessing the season data\n",
    "            processed_df = preprocess_season(file_name, year, mvp_votings)\n",
    "            processed_df.to_csv(output_file, index=False)\n",
    "            print(f\"Processed {season} successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {season}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {file_name} not found. Skipping.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a 1 min break before running the next cell to avoid getting locked out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2008-09 successfully!\n",
      "Processed 2009-10 successfully!\n",
      "Processed 2010-11 successfully!\n",
      "Processed 2011-12 successfully!\n",
      "Processed 2012-13 successfully!\n",
      "Processed 2013-14 successfully!\n",
      "Processed 2014-15 successfully!\n",
      "Processed 2015-16 successfully!\n",
      "Processed 2016-17 successfully!\n",
      "Processed 2017-18 successfully!\n",
      "Processed 2018-19 successfully!\n",
      "Processed 2019-20 successfully!\n",
      "Processed 2020-21 successfully!\n",
      "Processed 2021-22 successfully!\n"
     ]
    }
   ],
   "source": [
    "# continuation 2008-2021\n",
    "input_folder = \"untouched_seasonal_data\"\n",
    "output_folder = \"processed_data_with_Team_Rank\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# processing files for each season\n",
    "for year in range(2008, 2022):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}.csv\"\n",
    "    output_file = f\"{output_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            # fetching MVP voting data for the season\n",
    "            mvp_data = nba.get_award_votings('mvp', year)\n",
    "            mvp_votings = set(mvp_data['Player']) \n",
    "            \n",
    "            # preprocessing the season data\n",
    "            processed_df = preprocess_season(file_name, year, mvp_votings)\n",
    "            processed_df.to_csv(output_file, index=False)\n",
    "            print(f\"Processed {season} successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {season}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {file_name} not found. Skipping.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a 1 min break before running the next cell to avoid getting locked out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2022-23 successfully!\n",
      "Processed 2023-24 successfully!\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"untouched_seasonal_data\"\n",
    "output_folder = \"processed_data_with_Team_Rank\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# processing files for each season\n",
    "for year in range(2022, 2024):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}.csv\"\n",
    "    output_file = f\"{output_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            # fetching MVP voting data for the season\n",
    "            mvp_data = nba.get_award_votings('mvp', year)\n",
    "            mvp_votings = set(mvp_data['Player']) \n",
    "            \n",
    "            # preprocessing the season data\n",
    "            processed_df = preprocess_season(file_name, year, mvp_votings)\n",
    "            processed_df.to_csv(output_file, index=False)\n",
    "            print(f\"Processed {season} successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {season}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {file_name} not found. Skipping.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2024-25 season successfully\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "input_file = \"untouched_seasonal_data/nba_player_stats_2024-25.csv\"\n",
    "output_file = \"processed_data_with_Team_Rank/nba_player_stats_2024-25_processed.csv\"\n",
    "\n",
    "# Team mapping for abbreviations\n",
    "team_mapping = {\n",
    "    'MIL': 'Milwaukee Bucks',\n",
    "    'BOS': 'Boston Celtics',\n",
    "    'PHI': 'Philadelphia 76ers',\n",
    "    'CLE': 'Cleveland Cavaliers',\n",
    "    'NYK': 'New York Knicks',\n",
    "    'BRK': 'Brooklyn Nets',\n",
    "    'ATL': 'Atlanta Hawks',\n",
    "    'MIA': 'Miami Heat',\n",
    "    'CHI': 'Chicago Bulls',\n",
    "    'TOR': 'Toronto Raptors',\n",
    "    'IND': 'Indiana Pacers',\n",
    "    'DET': 'Detroit Pistons',\n",
    "    'ORL': 'Orlando Magic',\n",
    "    'CHO': 'Charlotte Hornets',\n",
    "    'WAS': 'Washington Wizards',\n",
    "    'DEN': 'Denver Nuggets',\n",
    "    'MIN': 'Minnesota Timberwolves',\n",
    "    'OKC': 'Oklahoma City Thunder',\n",
    "    'POR': 'Portland Trail Blazers',\n",
    "    'UTA': 'Utah Jazz',\n",
    "    'GSW': 'Golden State Warriors',\n",
    "    'LAC': 'Los Angeles Clippers',\n",
    "    'SAC': 'Sacramento Kings',\n",
    "    'PHO': 'Phoenix Suns',\n",
    "    'LAL': 'Los Angeles Lakers',\n",
    "    'DAL': 'Dallas Mavericks',\n",
    "    'MEM': 'Memphis Grizzlies',\n",
    "    'NOP': 'New Orleans Pelicans',\n",
    "    'SAS': 'San Antonio Spurs',\n",
    "    'HOU': 'Houston Rockets'\n",
    "}\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Initialize the new columns with default values\n",
    "df['Team_Rank'] = -1\n",
    "df['Made_Playoffs'] = 0\n",
    "\n",
    "standings = nba.get_standings(2025, info='total')\n",
    "\n",
    "# cleaning the team names in standings\n",
    "standings['Tm'] = standings['Tm'].str.replace(r'\\s*\\([0-9]+\\)', '', regex=True)\n",
    "standings['Tm'] = standings['Tm'].str.replace(\"*\", \"\").str.strip()\n",
    "\n",
    "# creating mapping of team names to rankings\n",
    "team_rank_map = dict(zip(standings['Tm'], standings['Seed']))\n",
    "\n",
    "# mapping team abbreviations to full names and then to rankings\n",
    "df['Team_Full'] = df['Team'].map(team_mapping)\n",
    "df['Team_Rank'] = df['Team_Full'].map(team_rank_map).fillna(-1).astype(int)\n",
    "\n",
    "# Drop the temporary full team name column\n",
    "df.drop(columns=['Team_Full'], inplace=True)\n",
    "\n",
    "# dropping unnecessary columns\n",
    "drop_columns = ['Age', 'Pos', 'GS', '3PA', '2PA', 'PF', 'Awards']\n",
    "df = df.drop(columns=drop_columns, errors='ignore')\n",
    "\n",
    "multi_team_players = df[df['Team'] == '2TM']['Player'].unique()\n",
    "mask = (df['Team'] == '2TM') | (~df['Player'].isin(multi_team_players))\n",
    "df = df[mask]\n",
    "\n",
    "# calculating TS%\n",
    "if 'PTS' in df.columns and 'FGA' in df.columns and 'FTA' in df.columns:\n",
    "    df['TS%'] = df['PTS'] / (2 * (df['FGA'] + 0.44 * df['FTA']))\n",
    "    df['TS%'] = df['TS%'].round(2)\n",
    "\n",
    "# calculating missed shots for EFF\n",
    "if 'FGA' in df.columns and 'FG' in df.columns:\n",
    "    df['Missed_FG'] = df['FGA'] - df['FG']\n",
    "if 'FTA' in df.columns and 'FT' in df.columns:\n",
    "    df['Missed_FT'] = df['FTA'] - df['FT']\n",
    "\n",
    "# calculating the EFF metric\n",
    "if {'PTS', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'G', 'Missed_FG', 'Missed_FT'}.issubset(df.columns):\n",
    "    df['EFF'] = (\n",
    "        df['PTS'] +\n",
    "        df['TRB'] +\n",
    "        df['AST'] +\n",
    "        df['STL'] +\n",
    "        df['BLK'] -\n",
    "        df['Missed_FG'] -\n",
    "        df['Missed_FT'] -\n",
    "        df['TOV']\n",
    "    ) / df['G']\n",
    "    df['EFF'] = df['EFF'].round(2)\n",
    "\n",
    "# dropping the temporary columns\n",
    "df.drop(columns=['Missed_FG', 'Missed_FT'], inplace=True, errors='ignore')\n",
    "\n",
    "# adding the Nominated column\n",
    "df['Nominated'] = df['Player'].apply(lambda player: 1 if player in mvp_votings else 0)\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv(output_file, index=False)\n",
    "print(\"Processed 2024-25 season successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data for season 1980-81\n",
      "Successfully loaded data for season 1981-82\n",
      "Successfully loaded data for season 1982-83\n",
      "Successfully loaded data for season 1983-84\n",
      "Successfully loaded data for season 1984-85\n",
      "Successfully loaded data for season 1985-86\n",
      "Successfully loaded data for season 1986-87\n",
      "Successfully loaded data for season 1987-88\n",
      "Successfully loaded data for season 1988-89\n",
      "Successfully loaded data for season 1989-90\n",
      "Successfully loaded data for season 1990-91\n",
      "Successfully loaded data for season 1991-92\n",
      "Successfully loaded data for season 1992-93\n",
      "Successfully loaded data for season 1993-94\n",
      "Successfully loaded data for season 1994-95\n",
      "Successfully loaded data for season 1995-96\n",
      "Successfully loaded data for season 1996-97\n",
      "Successfully loaded data for season 1997-98\n",
      "Successfully loaded data for season 1998-99\n",
      "Successfully loaded data for season 1999-00\n",
      "Successfully loaded data for season 2000-01\n",
      "Successfully loaded data for season 2001-02\n",
      "Successfully loaded data for season 2002-03\n",
      "Successfully loaded data for season 2003-04\n",
      "Successfully loaded data for season 2004-05\n",
      "Successfully loaded data for season 2005-06\n",
      "Successfully loaded data for season 2006-07\n",
      "Successfully loaded data for season 2007-08\n",
      "Successfully loaded data for season 2008-09\n",
      "Successfully loaded data for season 2009-10\n",
      "Successfully loaded data for season 2010-11\n",
      "Successfully loaded data for season 2011-12\n",
      "Successfully loaded data for season 2012-13\n",
      "Successfully loaded data for season 2013-14\n",
      "Successfully loaded data for season 2014-15\n",
      "Successfully loaded data for season 2015-16\n",
      "Successfully loaded data for season 2016-17\n",
      "All datasets have been concatenated and saved to 'nba_combined_1980_2015_with_Team_Rank.csv'.\n",
      "\n",
      "Verification Information:\n",
      "Total number of rows: 15607\n",
      "Number of unique seasons: 37\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"processed_data_with_Team_Rank\"\n",
    "output_folder = \"processed_data_with_Team_Rank\"\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "all_dataframes = []\n",
    "\n",
    "# Process each season from 1980 to 2015-16\n",
    "for year in range(1980, 2017):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"  # Creates strings like \"1980-81\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    try:\n",
    "        # Read the CSV file with no data type inference to preserve original values\n",
    "        df = pd.read_csv(file_name, dtype=str)\n",
    "        all_dataframes.append(df)\n",
    "        print(f\"Successfully loaded data for season {season}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Could not find file for season {season}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing season {season}: {str(e)}\")\n",
    "\n",
    "# Combine all dataframes with pure concatenation\n",
    "if all_dataframes:\n",
    "    nba_combined_1980_2015_with_Team_Rank = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Save the combined dataframe to a CSV file without any modifications\n",
    "    nba_combined_1980_2015_with_Team_Rank.to_csv(\"nba_combined_1980_2015_with_Team_Rank.csv\", index=False)\n",
    "    print(\"All datasets have been concatenated and saved to 'nba_combined_1980_2015_with_Team_Rank.csv'.\")\n",
    "    \n",
    "    # Print basic verification information\n",
    "    print(\"\\nVerification Information:\")\n",
    "    print(f\"Total number of rows: {len(nba_combined_1980_2015_with_Team_Rank)}\")\n",
    "    print(f\"Number of unique seasons: {len(nba_combined_1980_2015_with_Team_Rank['Season'].unique())}\")\n",
    "else:\n",
    "    print(\"No data was found to combine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data for season 2016-17\n",
      "Successfully loaded data for season 2017-18\n",
      "Successfully loaded data for season 2018-19\n",
      "Successfully loaded data for season 2019-20\n",
      "Successfully loaded data for season 2020-21\n",
      "Successfully loaded data for season 2021-22\n",
      "Successfully loaded data for season 2022-23\n",
      "Successfully loaded data for season 2023-24\n",
      "Successfully loaded data for season 2024-25\n",
      "All datasets have been concatenated and saved to 'nba_combined_2016_2024_with_Team_Rank.csv'.\n",
      "\n",
      "Verification Information:\n",
      "Total number of rows: 4974\n",
      "Number of unique seasons: 9\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"processed_data_with_Team_Rank\"\n",
    "output_folder = \"processed_data_with_Team_Rank\"\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "all_dataframes = []\n",
    "\n",
    "# Process each season from 2016 to 2024\n",
    "for year in range(2016, 2025):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"  # Creates strings like \"2016-17\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    try:\n",
    "        # Read the CSV file with no data type inference to preserve original values\n",
    "        df = pd.read_csv(file_name, dtype=str)\n",
    "        all_dataframes.append(df)\n",
    "        print(f\"Successfully loaded data for season {season}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Could not find file for season {season}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing season {season}: {str(e)}\")\n",
    "\n",
    "# Combine all dataframes with pure concatenation\n",
    "if all_dataframes:\n",
    "    nba_combined_2016_2024_with_Team_Rank = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Save the combined dataframe to a CSV file without any modifications\n",
    "    nba_combined_2016_2024_with_Team_Rank.to_csv(\"nba_combined_2016_2024_with_Team_Rank.csv\", index=False)\n",
    "    print(\"All datasets have been concatenated and saved to 'nba_combined_2016_2024_with_Team_Rank.csv'.\")\n",
    "    \n",
    "    # Print basic verification information\n",
    "    print(\"\\nVerification Information:\")\n",
    "    print(f\"Total number of rows: {len(nba_combined_2016_2024_with_Team_Rank)}\")\n",
    "    print(f\"Number of unique seasons: {len(nba_combined_2016_2024_with_Team_Rank['Season'].unique())}\")\n",
    "else:\n",
    "    print(\"No data was found to combine.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Succefully itegrated Team_Rank and Made_Playoffs column.\n",
    "\n",
    "Team_Rank holds the players current team ranking.\n",
    "\n",
    "Made_Playoffs holds a binary value, 1 if the team made the playoffs that year, otherwise 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
