{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BRScraper import nba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing for ML Model\n",
    "\n",
    "# df = nba.get_stats(season=2023, info='per_game', playoffs=False)\n",
    "# drop_columns = ['Age','Pos', 'GS', '3PA', '2PA', 'PF', 'Awards']\n",
    "# df_cleaned = df.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Joel Embiid', 'Nikola Jokić', 'Giannis Antetokounmpo', 'Jayson Tatum', 'Shai Gilgeous-Alexander', 'Donovan Mitchell', 'Domantas Sabonis', 'Luka Dončić', 'Stephen Curry', 'Jimmy Butler', \"De'Aaron Fox\", 'Jalen Brunson', 'Ja Morant']\n"
     ]
    }
   ],
   "source": [
    "# mvp_data = nba.get_award_votings('mvp', 2023)\n",
    "# nominated_players = mvp_data['Player'].tolist()\n",
    "# print(nominated_players)\n",
    "\n",
    "# creating the 'Previously_Nominated' column, if a player was nominated for MVP mark 1, else mark 0. will help serve as a proxy for player reputation\n",
    "# df_cleaned['Previously_Nominated'] = df_cleaned['Player'].apply(lambda x: 1 if x in nominated_players else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # identifying players who have stats for multiple teams and eliminating duplicates\n",
    "# multi_team_players = df_cleaned[df_cleaned['Team'] == '2TM']['Player'].unique()\n",
    "\n",
    "# # keeping only the row where team value is set to 2TM, this row will include all combined stats and average from all teams the player played for\n",
    "# mask = (df_cleaned['Team'] == '2TM') | (~df_cleaned['Player'].isin(multi_team_players))\n",
    "\n",
    "# df_cleaned = df_cleaned[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating a True Shooting Percentage (TS%) column\n",
    "# # the formula is TS% = PTS / 2 * (FGA + 0.44 * FTA)\n",
    "\n",
    "# if 'PTS' in df_cleaned.columns and 'FGA' in df_cleaned.columns and 'FTA' in df_cleaned.columns:\n",
    "#     df_cleaned['TS%'] = df_cleaned['PTS'] / (2 * (df_cleaned['FGA'] + 0.44 * df_cleaned['FTA']))\n",
    "#     df_cleaned['TS%'] = df_cleaned['TS%'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding another column EEF, stands effeciency. It a metric used by the nba to calculate a player's efficiency or impact.\n",
    "\n",
    "# # calculating missed field goals and missed free throws because the EEF formula requires it.\n",
    "# df_cleaned['Missed_FG'] = df_cleaned['FGA'] - df_cleaned['FG']\n",
    "# df_cleaned['Missed_FT'] = df_cleaned['FTA'] - df_cleaned['FT']\n",
    "\n",
    "# # Calculating EFF\n",
    "# df_cleaned['EFF'] = (\n",
    "#     df_cleaned['PTS'] +\n",
    "#     df_cleaned['TRB'] +\n",
    "#     df_cleaned['AST'] +\n",
    "#     df_cleaned['STL'] +\n",
    "#     df_cleaned['BLK'] -\n",
    "#     df_cleaned['Missed_FG'] -\n",
    "#     df_cleaned['Missed_FT'] -\n",
    "#     df_cleaned['TOV']\n",
    "#     ) / df_cleaned['G']\n",
    "\n",
    "# # dropping the temporary columns, no longer needed\n",
    "# df_cleaned.drop(columns=['Missed_FG', 'Missed_FT'], inplace=True)\n",
    "\n",
    "# # rounded EFF to 2 decimals\n",
    "# df_cleaned['EFF'] = df_cleaned['EFF'].round(2)\n",
    "\n",
    "# output_file = \"nba_2023_adjusted_data.csv\"\n",
    "# df_cleaned.to_csv(output_file, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO NOT RUN THE CELL BELOW, YOU WILL BE TIMED OUT AFTER 30 CONSECUTIVE REQUESTS.\n",
    "THIS IS STRICTLY FOR PREPROCESSING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1980-81 successfully!\n",
      "Processed 1981-82 successfully!\n",
      "Processed 1982-83 successfully!\n",
      "Processed 1983-84 successfully!\n",
      "Processed 1984-85 successfully!\n",
      "Processed 1985-86 successfully!\n",
      "Processed 1986-87 successfully!\n",
      "Processed 1987-88 successfully!\n",
      "Processed 1988-89 successfully!\n",
      "Processed 1989-90 successfully!\n",
      "Processed 1990-91 successfully!\n",
      "Processed 1991-92 successfully!\n",
      "Processed 1992-93 successfully!\n",
      "Processed 1993-94 successfully!\n",
      "Processed 1994-95 successfully!\n",
      "Processed 1995-96 successfully!\n",
      "Processed 1996-97 successfully!\n",
      "Processed 1997-98 successfully!\n",
      "Processed 1998-99 successfully!\n",
      "Processed 1999-00 successfully!\n",
      "Processed 2000-01 successfully!\n",
      "Processed 2001-02 successfully!\n",
      "Processed 2002-03 successfully!\n",
      "Processed 2003-04 successfully!\n",
      "Processed 2004-05 successfully!\n",
      "Processed 2005-06 successfully!\n",
      "Processed 2006-07 successfully!\n",
      "Processed 2007-08 successfully!\n",
      "Processed 2008-09 successfully!\n",
      "Processed 2009-10 successfully!\n",
      "Error processing 2010-11: 2010 is not a valid season.\n",
      "Error processing 2011-12: 2011 is not a valid season.\n",
      "Error processing 2012-13: 2012 is not a valid season.\n",
      "Error processing 2013-14: 2013 is not a valid season.\n",
      "Error processing 2014-15: 2014 is not a valid season.\n",
      "Error processing 2015-16: 2015 is not a valid season.\n",
      "Error processing 2016-17: 2016 is not a valid season.\n",
      "Error processing 2017-18: 2017 is not a valid season.\n",
      "Error processing 2018-19: 2018 is not a valid season.\n",
      "Error processing 2019-20: 2019 is not a valid season.\n",
      "Error processing 2020-21: 2020 is not a valid season.\n",
      "Error processing 2021-22: 2021 is not a valid season.\n",
      "Error processing 2022-23: 2022 is not a valid season.\n",
      "Error processing 2023-24: 2023 is not a valid season.\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess a single season\n",
    "def preprocess_season(file_name, season, mvp_votings):\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    # dropping unnecessary columns\n",
    "    drop_columns = ['Age', 'Pos', 'GS', '3PA', '2PA', 'PF', 'Awards']\n",
    "    df_cleaned = df.drop(columns=drop_columns, errors='ignore')\n",
    "\n",
    "    # handling players who played for multiple teams\n",
    "    multi_team_players = df_cleaned[df_cleaned['Team'] == '2TM']['Player'].unique()\n",
    "    mask = (df_cleaned['Team'] == '2TM') | (~df_cleaned['Player'].isin(multi_team_players))\n",
    "    df_cleaned = df_cleaned[mask]\n",
    "\n",
    "    # calculating TS%\n",
    "    if 'PTS' in df_cleaned.columns and 'FGA' in df_cleaned.columns and 'FTA' in df_cleaned.columns:\n",
    "        df_cleaned['TS%'] = df_cleaned['PTS'] / (2 * (df_cleaned['FGA'] + 0.44 * df_cleaned['FTA']))\n",
    "        df_cleaned['TS%'] = df_cleaned['TS%'].round(2)\n",
    "\n",
    "    # calculating missed shots for EFF\n",
    "    if 'FGA' in df_cleaned.columns and 'FG' in df_cleaned.columns:\n",
    "        df_cleaned['Missed_FG'] = df_cleaned['FGA'] - df_cleaned['FG']\n",
    "    if 'FTA' in df_cleaned.columns and 'FT' in df_cleaned.columns:\n",
    "        df_cleaned['Missed_FT'] = df_cleaned['FTA'] - df_cleaned['FT']\n",
    "\n",
    "    # calculating the EFF metric\n",
    "    if {'PTS', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'G', 'Missed_FG', 'Missed_FT'}.issubset(df_cleaned.columns):\n",
    "        df_cleaned['EFF'] = (\n",
    "            df_cleaned['PTS'] +\n",
    "            df_cleaned['TRB'] +\n",
    "            df_cleaned['AST'] +\n",
    "            df_cleaned['STL'] +\n",
    "            df_cleaned['BLK'] -\n",
    "            df_cleaned['Missed_FG'] -\n",
    "            df_cleaned['Missed_FT'] -\n",
    "            df_cleaned['TOV']\n",
    "        ) / df_cleaned['G']\n",
    "        df_cleaned['EFF'] = df_cleaned['EFF'].round(2)\n",
    "\n",
    "    # dropping the temporary columns\n",
    "    df_cleaned.drop(columns=['Missed_FG', 'Missed_FT'], inplace=True, errors='ignore')\n",
    "\n",
    "    # adding the MVP_Rank column\n",
    "    df_cleaned['MVP_Rank'] = None  # Initialize with blank values\n",
    "\n",
    "    # adding the Nominated column\n",
    "    df_cleaned['Nominated'] = df_cleaned['Player'].apply(lambda player: 1 if player in mvp_votings else 0)\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "# declaring the folder containing the CSV files and output destination\n",
    "input_folder = \"untouched_seasonal_data\"\n",
    "output_folder = \"processed_data\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# processing files for each season\n",
    "for year in range(1980, 2024):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}.csv\"\n",
    "    output_file = f\"{output_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            # fetching MVP voting data for the season\n",
    "            mvp_data = nba.get_award_votings('mvp', year)\n",
    "            mvp_votings = set(mvp_data['Player'])  # Extract players nominated for MVP\n",
    "            \n",
    "            # preprocessing the season data\n",
    "            processed_df = preprocess_season(file_name, year, mvp_votings)\n",
    "            processed_df.to_csv(output_file, index=False)\n",
    "            print(f\"Processed {season} successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {season}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {file_name} not found. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2010-11 successfully!\n",
      "Processed 2011-12 successfully!\n",
      "Processed 2012-13 successfully!\n",
      "Processed 2013-14 successfully!\n",
      "Processed 2014-15 successfully!\n",
      "Processed 2015-16 successfully!\n",
      "Processed 2016-17 successfully!\n",
      "Processed 2017-18 successfully!\n",
      "Processed 2018-19 successfully!\n",
      "Processed 2019-20 successfully!\n",
      "Processed 2020-21 successfully!\n",
      "Processed 2021-22 successfully!\n",
      "Processed 2022-23 successfully!\n",
      "Processed 2023-24 successfully!\n"
     ]
    }
   ],
   "source": [
    "def preprocess_season(file_name, season, mvp_votings):\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    # dropping unnecessary columns\n",
    "    drop_columns = ['Age', 'Pos', 'GS', '3PA', '2PA', 'PF', 'Awards']\n",
    "    df_cleaned = df.drop(columns=drop_columns, errors='ignore')\n",
    "\n",
    "    # handling players who played for multiple teams\n",
    "    multi_team_players = df_cleaned[df_cleaned['Team'] == '2TM']['Player'].unique()\n",
    "    mask = (df_cleaned['Team'] == '2TM') | (~df_cleaned['Player'].isin(multi_team_players))\n",
    "    df_cleaned = df_cleaned[mask]\n",
    "\n",
    "    # calculating TS%\n",
    "    if 'PTS' in df_cleaned.columns and 'FGA' in df_cleaned.columns and 'FTA' in df_cleaned.columns:\n",
    "        df_cleaned['TS%'] = df_cleaned['PTS'] / (2 * (df_cleaned['FGA'] + 0.44 * df_cleaned['FTA']))\n",
    "        df_cleaned['TS%'] = df_cleaned['TS%'].round(2)\n",
    "\n",
    "    # calculating missed shots for EFF\n",
    "    if 'FGA' in df_cleaned.columns and 'FG' in df_cleaned.columns:\n",
    "        df_cleaned['Missed_FG'] = df_cleaned['FGA'] - df_cleaned['FG']\n",
    "    if 'FTA' in df_cleaned.columns and 'FT' in df_cleaned.columns:\n",
    "        df_cleaned['Missed_FT'] = df_cleaned['FTA'] - df_cleaned['FT']\n",
    "\n",
    "    # calculating the EFF metric\n",
    "    if {'PTS', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'G', 'Missed_FG', 'Missed_FT'}.issubset(df_cleaned.columns):\n",
    "        df_cleaned['EFF'] = (\n",
    "            df_cleaned['PTS'] +\n",
    "            df_cleaned['TRB'] +\n",
    "            df_cleaned['AST'] +\n",
    "            df_cleaned['STL'] +\n",
    "            df_cleaned['BLK'] -\n",
    "            df_cleaned['Missed_FG'] -\n",
    "            df_cleaned['Missed_FT'] -\n",
    "            df_cleaned['TOV']\n",
    "        ) / df_cleaned['G']\n",
    "        df_cleaned['EFF'] = df_cleaned['EFF'].round(2)\n",
    "\n",
    "    # dropping the temporary columns\n",
    "    df_cleaned.drop(columns=['Missed_FG', 'Missed_FT'], inplace=True, errors='ignore')\n",
    "\n",
    "    # adding the MVP_Rank column\n",
    "    df_cleaned['MVP_Rank'] = None  # Initialize with blank values\n",
    "\n",
    "    # adding the Nominated column\n",
    "    df_cleaned['Nominated'] = df_cleaned['Player'].apply(lambda player: 1 if player in mvp_votings else 0)\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "# declaring the folder containing the CSV files and output destination\n",
    "input_folder = \"untouched_seasonal_data\"\n",
    "output_folder = \"processed_data\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# processing files for each season\n",
    "for year in range(2010, 2024):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}.csv\"\n",
    "    output_file = f\"{output_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            # fetching MVP voting data for the season\n",
    "            mvp_data = nba.get_award_votings('mvp', year)\n",
    "            mvp_votings = set(mvp_data['Player'])  # Extract players nominated for MVP\n",
    "            \n",
    "            # preprocessing the season data\n",
    "            processed_df = preprocess_season(file_name, year, mvp_votings)\n",
    "            processed_df.to_csv(output_file, index=False)\n",
    "            print(f\"Processed {season} successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {season}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {file_name} not found. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read data for the 1980 season\n",
      "Successfully read data for the 1981 season\n",
      "Successfully read data for the 1982 season\n",
      "Successfully read data for the 1983 season\n",
      "Successfully read data for the 1984 season\n",
      "Successfully read data for the 1985 season\n",
      "Successfully read data for the 1986 season\n",
      "Successfully read data for the 1987 season\n",
      "Successfully read data for the 1988 season\n",
      "Successfully read data for the 1989 season\n",
      "Successfully read data for the 1990 season\n",
      "Successfully read data for the 1991 season\n",
      "Successfully read data for the 1992 season\n",
      "Successfully read data for the 1993 season\n",
      "Successfully read data for the 1994 season\n",
      "Successfully read data for the 1995 season\n",
      "Successfully read data for the 1996 season\n",
      "Successfully read data for the 1997 season\n",
      "Successfully read data for the 1998 season\n",
      "Successfully read data for the 1999 season\n",
      "Successfully read data for the 2000 season\n",
      "Successfully read data for the 2001 season\n",
      "Successfully read data for the 2002 season\n",
      "Successfully read data for the 2003 season\n",
      "Successfully read data for the 2004 season\n",
      "Successfully read data for the 2005 season\n",
      "Successfully read data for the 2006 season\n",
      "Successfully read data for the 2007 season\n",
      "Successfully read data for the 2008 season\n",
      "Successfully read data for the 2009 season\n",
      "Successfully read data for the 2010 season\n",
      "Successfully read data for the 2011 season\n",
      "Successfully read data for the 2012 season\n",
      "Successfully read data for the 2013 season\n",
      "Successfully read data for the 2014 season\n",
      "Successfully read data for the 2015 season\n",
      "All datasets have been concatenated and saved to 'nba_combined_1980_2015.csv'.\n"
     ]
    }
   ],
   "source": [
    "#Combine all datasets from 1980 to 2015\n",
    "# Define the folder containing the CSV files\n",
    "input_folder = \"processed_data\"\n",
    "output_folder = \"processed_data\"\n",
    "\n",
    "# List to hold dataframes\n",
    "dataframes = []\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Loop through each year from 1980 to 2015\n",
    "for year in range(1980, 2016):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            # Read the dataset for the year\n",
    "            df = pd.read_csv(file_name)\n",
    "        \n",
    "            # Append the dataframe to the list\n",
    "            dataframes.append(df)\n",
    "        \n",
    "            print(f\"Successfully read data for the {year} season\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read data for {year} season. Error: {e}\")\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "nba_combined_1980_2015 = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "#dropping the MVP_Rank column\n",
    "nba_combined_1980_2015 = nba_combined_1980_2015.drop(columns=['MVP_Rank'])\n",
    "\n",
    "# defining the MVP_Class column\n",
    "nba_combined_1980_2015['MVP_Class'] = 0\n",
    "\n",
    "\n",
    "# Save the combined dataframe to a CSV file\n",
    "nba_combined_1980_2015.to_csv(\"nba_combined_1980_2015.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\"All datasets have been concatenated and saved to 'nba_combined_1980_2015.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read data for the 2016 season\n",
      "Successfully read data for the 2017 season\n",
      "Successfully read data for the 2018 season\n",
      "Successfully read data for the 2019 season\n",
      "Successfully read data for the 2020 season\n",
      "Successfully read data for the 2021 season\n",
      "Successfully read data for the 2022 season\n",
      "Successfully read data for the 2023 season\n",
      "Successfully read data for the 2024 season\n",
      "All datasets have been concatenated and saved to 'nba_combined_2016_2024.csv'.\n"
     ]
    }
   ],
   "source": [
    "#Combine all datasets from 2016 to 2024\n",
    "# Define the folder containing the CSV files\n",
    "input_folder = \"processed_data\"\n",
    "output_folder = \"processed_data\"\n",
    "\n",
    "# List to hold dataframes\n",
    "dataframes = []\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Loop through each year from 2016 to 2024\n",
    "for year in range(2016, 2025):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            # Read the dataset for the year\n",
    "            df = pd.read_csv(file_name)\n",
    "        \n",
    "            # Append the dataframe to the list\n",
    "            dataframes.append(df)\n",
    "        \n",
    "            print(f\"Successfully read data for the {year} season\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read data for {year} season. Error: {e}\")\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "nba_combined_2016_2024 = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "#dropping the MVP_Rank column\n",
    "nba_combined_2016_2024 = nba_combined_2016_2024.drop(columns=['MVP_Rank'])\n",
    "\n",
    "# defining the MVP_Class column\n",
    "nba_combined_2016_2024['MVP_Class'] = 0\n",
    "\n",
    "# Save the combined dataframe to a CSV file\n",
    "nba_combined_2016_2024.to_csv(\"nba_combined_2016_2024.csv\", index=False)\n",
    "\n",
    "print(\"All datasets have been concatenated and saved to 'nba_combined_2016_2024.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
